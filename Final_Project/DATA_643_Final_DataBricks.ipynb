{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "#from pyspark import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating \n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "#%matplotlib inline\n",
    "#conf = SparkConf().setAppName('ListenerSummarizer')\n",
    "#sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "#sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Sparsity finction\n",
    "def isSparse(array) :\n",
    "    m, n = array.shape\n",
    "    counter = 0\n",
    "  \n",
    "    # Count number of zeros\n",
    "    # in the matrix\n",
    "    for i in range(0,m) :\n",
    "        for j in range(0,n) :\n",
    "            if (array[i][j] == 0) :\n",
    "                counter = counter + 1\n",
    "  \n",
    "    return (counter * 100 / (m * n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "ratings_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/review_p.csv')\n",
    "business_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/business_p.csv')\n",
    "user_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/user_p.csv')\n",
    "\n",
    "business_pd['businessId'] = business_pd.index + 1\n",
    "user_pd['userId'] = user_pd.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply numeric value to ratings dataset\n",
    "ratings_pd = ratings_pd.merge(business_pd, how = 'left', left_on = 'business_id', right_on = 'business_id')\n",
    "ratings_pd = ratings_pd.merge(user_pd, how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "ratings_pd = ratings_pd[['businessId', 'userId', 'stars_x']]\n",
    "ratings_pd.columns = ['businessId','userId', 'stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sp_df = sqlContext.createDataFrame(ratings_pd)\n",
    "ratings_sp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rdd  = ratings_sp_df.rdd\n",
    "print(ratings_rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate datasets\n",
    "#Split dataset into train, validation and test sets\n",
    "rating_train, rating_val, rating_test= ratings_rdd.randomSplit([0.6, 0.2, 0.2])\n",
    "\n",
    "#Load data into memory\n",
    "rating_train.cache()\n",
    "rating_test.cache()\n",
    "rating_val.cache()\n",
    "\n",
    "#Sample results\n",
    "print('Train set')\n",
    "rating_train.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove ratings for validation and test datasets\n",
    "rating_test_no_rate = rating_test.map(lambda x: (x[0], x[1]))\n",
    "rating_val_no_rate = rating_val.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "#Load data into memory\n",
    "rating_test_no_rate.cache()\n",
    "rating_val_no_rate.cache()\n",
    "\n",
    "#Sample results\n",
    "print('Train set')\n",
    "rating_test_no_rate.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "import math\n",
    "rank = 1\n",
    "iterations = 10\n",
    "\n",
    "min_error = 0\n",
    "best_rank = -1\n",
    "\n",
    "for rank in range(5, 6):\n",
    "  for iterations in range(20, 25):\n",
    "    #generate model\n",
    "    model = ALS.train(rating_train, rank=rank, iterations=iterations)\n",
    "\n",
    "    #generate predictions\n",
    "    predictions = model.predictAll(rating_val_no_rate).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "    #get actual vs predictions\n",
    "    rates_and_preds = rating_val.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    \n",
    "\n",
    "\n",
    "    #calculate error\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "    #display output\n",
    "    print('For rank %s and %s the RMSE is %s' % (rank, iterations, error))\n",
    "\n",
    "    if error < min_error:\n",
    "        best_rank = rank\n",
    "\n",
    "    min_error = error\n",
    "        \n",
    "print('The best model was trained with rank %s' % best_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "ratings_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/review_p.csv')\n",
    "business_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/business_p.csv')\n",
    "user_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/user_p.csv')\n",
    "\n",
    "business_pd['businessId'] = business_pd.index + 1\n",
    "user_pd['userId'] = user_pd.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply numeric value to ratings dataset\n",
    "ratings_pd = ratings_pd.merge(business_pd, how = 'left', left_on = 'business_id', right_on = 'business_id')\n",
    "ratings_pd = ratings_pd.merge(user_pd, how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "ratings_pd = ratings_pd[['businessId', 'stars_x', 'userId']]\n",
    "ratings_pd.columns = ['businessId', 'stars','userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate user-business ratings\n",
    "user_visits = ratings_pd.groupby(['userId']).size().sort_values(ascending=True)\n",
    "\n",
    "user_visits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_visits.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_visits = pd.DataFrame(user_visits)\n",
    "user_visits['userId'] = user_visits.index\n",
    "user_visits = user_visits.reset_index(drop=True)\n",
    "user_visits.columns = ['ratingCount','userId']\n",
    "rating_visits = user_visits.groupby(['ratingCount']).size().sort_values(ascending=True)\n",
    "rating_visits = pd.DataFrame(rating_visits)\n",
    "rating_visits['users'] = rating_visits.index\n",
    "rating_visits = rating_visits.reset_index(drop=True)\n",
    "rating_visits.columns = ['users','ratingCount']\n",
    "rating_visits = rating_visits.sort_values(by=['users'], ascending=False)\n",
    "rating_visits.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate user-business ratings\n",
    "business_visits = ratings_pd.groupby(['businessId']).size().sort_values(ascending=True)\n",
    "\n",
    "business_visits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_visits.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot dataframe userId as columns and businessId as columns\n",
    "ratings_df = ratings_pd.pivot(index = 'userId', columns ='businessId', values = 'stars').fillna(0)\n",
    "ratings_df['userId'] = ratings_df.index\n",
    "\n",
    "#Convert ratings dataframe to matrix\n",
    "rating_matrix = ratings_df.values\n",
    "\n",
    "#Check how sparse dataset is\n",
    "sparsity = isSparse(rating_matrix)\n",
    "print('Ratings Dataset is : {:.2f}% Sparse'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entire dataset mean\n",
    "rawmean = ratings_pd['stars'].mean()\n",
    "\n",
    "#Raw mean for user - user bias\n",
    "user_rawmean = pd.DataFrame(ratings_pd.groupby(['userId'])['stars'].mean() - rawmean)\n",
    "user_rawmean.columns = ['userBias']\n",
    "user_rawmean['userId'] = user_rawmean.index\n",
    "user_rawmean = user_rawmean.reset_index(drop=True)\n",
    "\n",
    "#Raw mean for business - business bias\n",
    "business_rawmean = pd.DataFrame(ratings_pd.groupby(['businessId'])['stars'].mean() - rawmean)\n",
    "business_rawmean.columns = ['businessBias']\n",
    "business_rawmean['businessId'] = business_rawmean.index\n",
    "business_rawmean = business_rawmean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert user X business matrix to rows format\n",
    "#Each rows with have user, business, rating\n",
    "predicted_ratings_CtoR = pd.melt(ratings_df, id_vars='userId')\n",
    "predicted_ratings_CtoR.columns = ['userId', 'businessId','stars']\n",
    "predicted_ratings_CtoR['businessId'] = predicted_ratings_CtoR['businessId'].astype(int)\n",
    "\n",
    "#Attach baseline average ratings\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR.merge(user_rawmean, how='left', left_on=['userId'], right_on = ['userId'])\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR.merge(business_rawmean, how='left', \n",
    "                                                      left_on=['businessId'], \n",
    "                                                      right_on = ['businessId'])\n",
    "\n",
    "#Update ratings for only missing values\n",
    "predicted_ratings_CtoR['stars'] = np.where(predicted_ratings_CtoR['stars'] == 0, \n",
    "                      rawmean + predicted_ratings_CtoR['userBias'] + predicted_ratings_CtoR['businessBias'], \n",
    "                      predicted_ratings_CtoR['stars'])\n",
    "\n",
    "#Since ratings are between 1 and 5 change accordingly\n",
    "predicted_ratings_CtoR.loc[predicted_ratings_CtoR['stars'] < 1, 'stars'] = 1\n",
    "predicted_ratings_CtoR.loc[predicted_ratings_CtoR['stars'] > 5, 'stars'] = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "DATA_643_Final",
  "notebookId": 3726176210822005
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
