{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 6.073432698591637e-16\n",
      "RMSE : 0.003 Frobenius Norm : 26.956 k-Value reduced by : 0 Singlar Value Ratio : 1.0\n",
      "RMSE : 0.006 Frobenius Norm : 54.874 k-Value reduced by : 171 Singlar Value Ratio : 0.985\n",
      "RMSE : 0.018 Frobenius Norm : 172.516 k-Value reduced by : 648 Singlar Value Ratio : 0.956\n",
      "RMSE : 0.03 Frobenius Norm : 292.556 k-Value reduced by : 1011 Singlar Value Ratio : 0.912\n",
      "RMSE : 0.043 Frobenius Norm : 413.046 k-Value reduced by : 1291 Singlar Value Ratio : 0.857\n",
      "RMSE : 0.054 Frobenius Norm : 526.038 k-Value reduced by : 1501 Singlar Value Ratio : 0.795\n",
      "RMSE : 0.065 Frobenius Norm : 630.098 k-Value reduced by : 1661 Singlar Value Ratio : 0.729\n"
     ]
    }
   ],
   "source": [
    "#Load libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load datasets\n",
    "ratings_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/review_p.csv')\n",
    "business_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/business_p.csv')\n",
    "user_pd = pd.read_csv('https://raw.githubusercontent.com/ncooper76/DATA_643_Group/master/Final_Project/user_p.csv')\n",
    "\n",
    "business_pd['businessId'] = business_pd.index + 1\n",
    "user_pd['userId'] = user_pd.index + 1\n",
    "\n",
    "ratings_pd = ratings_pd.merge(business_pd, how = 'left', left_on = 'business_id', right_on = 'business_id')\n",
    "ratings_pd = ratings_pd.merge(user_pd, how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "ratings_pd = ratings_pd[['businessId', 'stars_x', 'userId']]\n",
    "ratings_pd.columns = ['businessId', 'stars','userId']\n",
    "ratings_pd['visited'] = 1\n",
    "\n",
    "ratings_df = ratings_pd.pivot(index = 'userId', columns ='businessId', values = 'stars').fillna(0)\n",
    "\n",
    "rating_matrix = ratings_df.values\n",
    "user_ratings_mean = np.mean(rating_matrix, axis = 1)\n",
    "rating_bias = rating_matrix - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "U, sigma, Vt = np.linalg.svd(rating_bias, full_matrices=False)\n",
    "\n",
    "#Get diagonal sigma\n",
    "sigma_diag = np.diag(sigma)\n",
    "\n",
    "#Recalculate ratings\n",
    "predicted_ratings = np.dot(np.dot(U, sigma_diag), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "rmse = mean_squared_error(predicted_ratings, rating_matrix)**0.5\n",
    "print(\"RMSE : \" + str(rmse))\n",
    "\n",
    "#Lets loop through reducing k value\n",
    "r, c = rating_bias.shape\n",
    "k = min(r, c)\n",
    "for i in range(5, 40, 5):\n",
    "\n",
    "    # take columns less than k from U\n",
    "    U_p = U[:,:k]\n",
    "    # take rows less than k from V\n",
    "    V_p = Vt[:k,:]\n",
    "    # build the new S matrix with top k diagnal elements\n",
    "    S_p = np.zeros((k, k), int)\n",
    "    for j in range(k):\n",
    "        S_p[j][j] = sigma[j]\n",
    "    \n",
    "    #Recalculate ratings\n",
    "    predicted_ratings = np.dot(np.dot(U_p, S_p), V_p) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "    #Calculate error difference\n",
    "    diffM = rating_matrix - predicted_ratings\n",
    "    \n",
    "    #Frobenius Norm\n",
    "    frobeniusNorm = np.linalg.norm(diffM, 'fro')\n",
    "    \n",
    "    #Singular value ratio has to be 90%\n",
    "    if (k == min(r, c)):\n",
    "        sigma_ratio = round(sum(sigma**2)/sum(sigma**2),3)\n",
    "    else:\n",
    "        less_singular_values = sigma[ np.where( sigma >= i ) ]\n",
    "        sigma_ratio = round(sum(less_singular_values**2)/sum(sigma**2),3)\n",
    "    \n",
    "    \n",
    "    #RMSE\n",
    "    rmse = mean_squared_error(predicted_ratings, rating_matrix)**0.5\n",
    "    print(\"RMSE : \" + str(round(rmse,3)) + \n",
    "          ' Frobenius Norm : ' + str(round(frobeniusNorm,3)) + \n",
    "          ' k-Value reduced by : ' + str(min(r, c) - k) + \n",
    "          ' Singlar Value Ratio : ' + str(sigma_ratio)\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Eliminate rows with low sigma value\n",
    "    k = min(r, c) - sigma[ np.where( sigma < i ) ].size\n",
    "\n",
    "\n",
    "\n",
    "#Number of dimensions\n",
    "k = min(r, c) - 1011\n",
    "# take columns less than k from U\n",
    "U_p = U[:,:k]\n",
    "# take rows less than k from V\n",
    "V_p = Vt[:k,:]\n",
    "# build the new S matrix with top k diagnal elements\n",
    "S_p = np.zeros((k, k), int)\n",
    "for j in range(k):\n",
    "    S_p[j][j] = sigma[j]\n",
    "\n",
    "#Recalculate ratings\n",
    "predicted_ratings = np.dot(np.dot(U_p, S_p), V_p) + user_ratings_mean.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = pd.DataFrame(predicted_ratings)\n",
    "predicted_ratings['userId'] = predicted_ratings.index + 1\n",
    "predicted_ratings_CtoR = pd.melt(predicted_ratings, id_vars='userId')\n",
    "predicted_ratings_CtoR.columns = ['userId', 'businessId','predict']\n",
    "predicted_ratings_CtoR['businessId'] = predicted_ratings_CtoR['businessId'] + 1\n",
    "predicted_ratings_CtoR['businessId'] = predicted_ratings_CtoR['businessId'].astype(int)\n",
    "\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR.merge(ratings_pd, how='left', left_on=['userId','businessId'], right_on = ['userId','businessId'])\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR[['businessId', 'userId', 'predict','visited']]\n",
    "\n",
    "sample_data = predicted_ratings_CtoR[(predicted_ratings_CtoR['userId'] <= 3000)]\n",
    "\n",
    "train_data, test_data = train_test_split(sample_data, test_size =0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data[['businessId','predict','visited']],\n",
    "                     business_pd[['businessId','is_open','review_count','stars']],\n",
    "                     how='left', on='businessId')\n",
    "train_data = train_data.fillna(0)\n",
    "rest_train_X = train_data[['predict','is_open','review_count','stars']]\n",
    "rest_train_y = train_data[['visited']]\n",
    "\n",
    "test_data = pd.merge(test_data[['businessId','predict','visited']],\n",
    "                     business_pd[['businessId','is_open','review_count','stars']],\n",
    "                     how='left', on='businessId')\n",
    "test_data = test_data.fillna(0)\n",
    "rest_test_X = test_data[['predict','is_open','review_count','stars']]\n",
    "rest_test_y = test_data[['visited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del [[predicted_ratings_CtoR]]\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000533\n",
      "         Iterations 17\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                visited   No. Observations:              4634700\n",
      "Model:                          Logit   Df Residuals:                  4634696\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 14 Jul 2018   Pseudo R-squ.:                  0.9494\n",
      "Time:                        09:55:07   Log-Likelihood:                -2471.1\n",
      "converged:                       True   LL-Null:                       -48862.\n",
      "                                        LLR p-value:                     0.000\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "predict         21.6215      0.318     67.913      0.000      20.997      22.245\n",
      "is_open         -1.7125      0.102    -16.732      0.000      -1.913      -1.512\n",
      "review_count    -0.0010      0.001     -0.895      0.371      -0.003       0.001\n",
      "stars           -3.7640      0.042    -89.473      0.000      -3.846      -3.682\n",
      "================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.96 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(rest_train_y,rest_train_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#X = rest_train_X.values\n",
    "#y = rest_train_y.values.ravel()\n",
    "\n",
    "predictors = ['predict','is_open','stars']\n",
    "outcome = ['visited']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_data[predictors], train_data[outcome].values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_data[predictors])\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(test_data[predictors], test_data[outcome].values.ravel())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of dimensions\n",
    "k = min(r, c) - 1291\n",
    "# take columns less than k from U\n",
    "U_p = U[:,:k]\n",
    "# take rows less than k from V\n",
    "V_p = Vt[:k,:]\n",
    "# build the new S matrix with top k diagnal elements\n",
    "S_p = np.zeros((k, k), int)\n",
    "for j in range(k):\n",
    "    S_p[j][j] = sigma[j]\n",
    "\n",
    "#Recalculate ratings\n",
    "predicted_ratings = np.dot(np.dot(U_p, S_p), V_p) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "\n",
    "predicted_ratings = pd.DataFrame(predicted_ratings)\n",
    "predicted_ratings['userId'] = predicted_ratings.index + 1\n",
    "predicted_ratings_CtoR = pd.melt(predicted_ratings, id_vars='userId')\n",
    "predicted_ratings_CtoR.columns = ['userId', 'businessId','predict']\n",
    "predicted_ratings_CtoR['businessId'] = predicted_ratings_CtoR['businessId'] + 1\n",
    "predicted_ratings_CtoR['businessId'] = predicted_ratings_CtoR['businessId'].astype(int)\n",
    "\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR.merge(ratings_pd, how='left', left_on=['userId','businessId'], right_on = ['userId','businessId'])\n",
    "predicted_ratings_CtoR = predicted_ratings_CtoR[['businessId', 'userId', 'predict','visited']]\n",
    "\n",
    "sample_data = predicted_ratings_CtoR[(predicted_ratings_CtoR['userId'] <= 3000)]\n",
    "\n",
    "train_data, test_data = train_test_split(sample_data, test_size =0.3, random_state=0)\n",
    "\n",
    "train_data = pd.merge(train_data[['businessId','predict','visited']],\n",
    "                     business_pd[['businessId','is_open','review_count','stars']],\n",
    "                     how='left', on='businessId')\n",
    "train_data = train_data.fillna(0)\n",
    "rest_train_X = train_data[['predict','is_open','review_count','stars']]\n",
    "rest_train_y = train_data[['visited']]\n",
    "\n",
    "test_data = pd.merge(test_data[['businessId','predict','visited']],\n",
    "                     business_pd[['businessId','is_open','review_count','stars']],\n",
    "                     how='left', on='businessId')\n",
    "test_data = test_data.fillna(0)\n",
    "rest_test_X = test_data[['predict','is_open','review_count','stars']]\n",
    "rest_test_y = test_data[['visited']]\n",
    "\n",
    "import gc\n",
    "del [[predicted_ratings_CtoR]]\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000885\n",
      "         Iterations 17\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                visited   No. Observations:              4634700\n",
      "Model:                          Logit   Df Residuals:                  4634696\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 14 Jul 2018   Pseudo R-squ.:                  0.9161\n",
      "Time:                        11:27:42   Log-Likelihood:                -4101.0\n",
      "converged:                       True   LL-Null:                       -48862.\n",
      "                                        LLR p-value:                     0.000\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "predict         23.0763      0.287     80.362      0.000      22.513      23.639\n",
      "is_open         -1.6246      0.078    -20.868      0.000      -1.777      -1.472\n",
      "review_count    -0.0056      0.001     -6.701      0.000      -0.007      -0.004\n",
      "stars           -3.4037      0.030   -112.226      0.000      -3.463      -3.344\n",
      "================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.90 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(rest_train_y,rest_train_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#X = rest_train_X.values\n",
    "#y = rest_train_y.values.ravel()\n",
    "\n",
    "predictors = ['predict','is_open','stars']\n",
    "outcome = ['visited']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_data[predictors], train_data[outcome].values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_data[predictors])\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(test_data[predictors], test_data[outcome].values.ravel())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
