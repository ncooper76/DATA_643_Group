{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA 643 Project 5: Implementing a Recommender System on Spark\n",
    "_Nathan, Angus, Pavan_\n",
    "\n",
    "_The goal of this project is give you practice beginning to work with a distributed recommender system. It is sufficient for this assignment to build out your application on a single node._\n",
    "\n",
    "Adapt one of your recommendation systems to work with Apache Spark and compare the performance with your previous iteration. Consider the efficiency of the system and the added complexity of using Spark. You may complete the assignment using PySpark (Python), SparkR (R) , sparklyr (R), or Scala.\n",
    "\n",
    "Please include in your conclusion: For your given recommender systemâ€™s data, algorithm(s), and (envisioned) implementation, at what point would you see moving to a distributed platform such as Spark becoming necessary?\n",
    "\n",
    "We will build a movie recommender using _collaborative filtering_ with _Spark's Alternating Least Saqures implementation_. For the scope of the project, _ALS_ matrix factorization results will be compared with the SVD matrix factorization we built in Project 3. \n",
    "\n",
    "#### Dataset\n",
    "\n",
    "We will be using [MovieLens Latest Datasets](https://grouplens.org/datasets/movielens/). GroupLens Research maintains movie rating data sets collected from the website [MovieLens](http://movielens.org). The datasets were collected over various periods of time, depending on the size of the set. For the scope of the project, we will be using _small dataset_ that contains 100,000 ratings and 1,300 tag applications applied to 9,000 movies by 670 users. The dataset will be split into a training and test sets, to measure the accuracy of the estimations of training set against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '31', '2.5'],\n",
       " ['1', '1029', '3.0'],\n",
       " ['1', '1061', '3.0'],\n",
       " ['1', '1129', '2.0'],\n",
       " ['1', '1172', '4.0']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import urllib.request #read dataset from GitHib\n",
    "import math\n",
    "\n",
    "#Functions\n",
    "def split_csv_data(str):\n",
    "    l = str.split(\",\")\n",
    "    return [l[0], l[1], l[2]]\n",
    "\n",
    "def dropFirstRow(index,iterator):\n",
    "     return iter(list(iterator)[1:]) if index==0 else iterator\n",
    "\n",
    "#Initialize the environment\n",
    "conf = SparkConf().setAppName('ALSTest')\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "#Get the movielens data\n",
    "#Save the file as local copy\n",
    "f = urllib.request.urlretrieve (\"https://raw.githubusercontent.com/akulapa/Data643-Week02/master/Data/ratings.csv\", \"ratings.csv\")\n",
    "data_file = \"./ratings.csv\"\n",
    "ratings_RDD = sc.textFile(data_file)\n",
    "\n",
    "#Remove timestamp column from the dataset\n",
    "ratings_RDD = ratings_RDD.map(lambda line: split_csv_data(line))\n",
    "\n",
    "#Remove the header from the dataset\n",
    "ratings_RDD = ratings_RDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "#Print output\n",
    "ratings_RDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is converted into _Resilient Distributed Dataset_, RDD. Data is stored as lists in RDD. First value is _userId_, second is _movieId_ and last one is _rating._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=31, rating=2.5),\n",
       " Rating(user=1, product=1029, rating=3.0),\n",
       " Rating(user=1, product=1061, rating=3.0),\n",
       " Rating(user=1, product=1129, rating=2.0),\n",
       " Rating(user=1, product=1172, rating=4.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert values in numeric values\n",
    "ratings= ratings_RDD.map(lambda l: Rating(int(l[0]),int(l[1]),float(l[2])))\n",
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ratings_ function in _pyspark.mllib.recommendation_, converts dataset into named lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=1129, rating=2.0),\n",
       " Rating(user=1, product=1172, rating=4.0),\n",
       " Rating(user=1, product=1263, rating=2.0),\n",
       " Rating(user=1, product=1293, rating=2.0),\n",
       " Rating(user=1, product=1339, rating=3.5)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate datasets\n",
    "#Split dataset into train, validation and test sets\n",
    "movie_train, movie_val, movie_test= ratings.randomSplit([0.6, 0.2, 0.2])\n",
    "\n",
    "#Load data into memory\n",
    "movie_train.cache()\n",
    "movie_test.cache()\n",
    "movie_val.cache()\n",
    "\n",
    "#Sample results\n",
    "print('Train set')\n",
    "movie_train.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS function takes input parameters\n",
    "\n",
    "- Training dataset\n",
    "- rank, is the number of latent or hidden factors in the model. Example, when user1 rates a movie as 4 and user2 rates the same movie as 3 there is some feature of the user that makes them rate in a certain way. It could be age, gender or location, etc. If for sure we know the factors that impact the user we could use the number directly. In this case, it would be 3. Since we don't know the features we can start with 1 and increment is until there is no improvement in the results.\n",
    "- iterations, ALS starts with a default value and improves one matrix at a time. This parameter defines number times to loop through.\n",
    "\n",
    "Best way to determine optimal values of _rank_ and _iterations_ is by experimentation. We have split dataset into _train_, _validation_ and _test_ sets. We would \n",
    "\n",
    "The ALS function also takes in additional parameters. However, we have not experimented with them.\n",
    "\n",
    "Due to limited resources, we have experimented _rank_ values between 1 and 8, while _iterations_ between 1 and 5. Beyond these values, we received errors and application would crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3773] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove ratings for validation and test datasets\n",
    "movie_test_no_rate = movie_test.map(lambda x: (x[0], x[1]))\n",
    "movie_val_no_rate = movie_val.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "#Load data into memory\n",
    "movie_test_no_rate.cache()\n",
    "movie_val_no_rate.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 1 the RMSE is 2.7641191563759526\n",
      "For rank 2 the RMSE is 1.0587037064621716\n",
      "For rank 3 the RMSE is 1.0311751605822177\n",
      "For rank 4 the RMSE is 1.0592531605329332\n",
      "For rank 5 the RMSE is 1.119789915769175\n",
      "For rank 6 the RMSE is 1.121753195059547\n",
      "For rank 7 the RMSE is 1.1584403886549701\n",
      "The best model was trained with rank 3\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "rank = 1\n",
    "iterations = 5\n",
    "\n",
    "min_error = 0\n",
    "best_rank = -1\n",
    "\n",
    "for rank in range(1, 8):\n",
    "    #generate model\n",
    "    model = ALS.train(movie_train, rank=rank, iterations=iterations)\n",
    "\n",
    "    #generate predictions\n",
    "    predictions = model.predictAll(movie_val_no_rate).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "    #get actual vs predictions\n",
    "    rates_and_preds = movie_val.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "\n",
    "    #calculate error\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "    #display output\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "\n",
    "    if error < min_error:\n",
    "        best_rank = rank\n",
    "\n",
    "    min_error = error\n",
    "        \n",
    "print('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output _rank_ 3 yeilds lower error and suggests it is better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error = 1.0444940254408608\n"
     ]
    }
   ],
   "source": [
    "#generate the model with best rank and iterations\n",
    "rank = 3\n",
    "iterations = 5\n",
    "model = ALS.train(movie_train, rank=rank, iterations=iterations)\n",
    "\n",
    "#apply the model for test data.\n",
    "predictions = model.predictAll(movie_test_no_rate).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "# joining the prediction with the original test dataset\n",
    "ratesAndPreds = movie_test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "\n",
    "# calculating error\n",
    "RMSE = math.sqrt(ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "print(\"Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "- Due to system resource constraints, we could not test for best _iterations_ beyond 5.\n",
    "- MSE is higher for ALS with parameters(_rank_ = 3 and _iterations_ = 5) compared to SVD. ALS RMSE: 1.04, SVD RMSE : 0.254\n",
    "- Also, _rank_ 3 does not make much sense as many factors could influence user rating a movie. We could not experiment further due to system resource constraints.\n",
    "- However, we would still suggest ALS when resources are not of concern.\n",
    "- To test out ALS for more iterations, we ventured into _databricks_ platform.\n",
    "- _databricks_ platform is easy to setup and was able to take advantage of the libraries that are readily available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "- https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536\n",
    "- https://www.codementor.io/jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw\n",
    "- https://dataplatform.cloud.ibm.com/exchange/public/entry/view/5ad1c820f57809ddec9a040e37b2bd55\n",
    "- https://stackoverflow.com/questions/24718697/pyspark-drop-rows\n",
    "- https://stackoverflow.com/questions/30729656/what-is-rank-in-als-machine-learning-algorithm-in-apache-spark-mllib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
