{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA 643 Project 4: Accuracy and Beyond\n",
    "_Nathan, Angus, Pavan_\n",
    "\n",
    "_The goal of this assignment is give you practice working with accuracy and other recommender system metrics._\n",
    "\n",
    "In this assignment you’re asked to do at least one or (if you like) both of the following:\n",
    "• Work in a small group, and/or\n",
    "• Choose a different dataset to work with from your previous projects.\n",
    "\n",
    "We are already in a small group, but wanted to examine the SVD matrix factorization system we built in Project 3 in greater detail so we opted to measure accuracy of that system. In this Jupyter Notebook, we will split the MovieLens data into a training and test set, and then measure the accuracy of the estimations from the training set against the test set.\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "We will be using [MovieLens Latest Datasets](https://grouplens.org/datasets/movielens/). GroupLens Research maintains movie rating data sets collected from the website [MovieLens](http://movielens.org). The datasets were collected over various periods of time, depending on the size of the set. For the scope of the project, we will be using _small dataset_ that contains 100,000 ratings and 1,300 tag applications applied to 9,000 movies by 670 users.\n",
    "\n",
    "#### Matrix Factorization via Singular Value Decomposition\n",
    "\n",
    "In simple terms _Matrix factorization_ is a process of breaking down a matrix into product of multiple matrices. There are many different ways to factor matrices, for the scope of the project we will be using singular value decomposition and generate recommendations.\n",
    "\n",
    "$$\\begin{equation}\n",
    "R = U\\Sigma V^{T}\n",
    "\\end{equation}$$\n",
    "\n",
    "where R is users's ratings matrix, $U$ is the user \"features\" matrix, $\\Sigma$ is the diagonal matrix of singular values (essentially weights), and $V^{T}$ is the movie \"features\" matrix. $U$ and $V^{T}$ are orthogonal, and represent different things. $U$ represents how much users \"like\" each feature and $V^{T}$ represents how relevant each feature is to each movie.\n",
    "\n",
    "To get the lower rank approximation, we take these matrices and keep only the top $k$ features, which we think of as the underlying tastes and preferences vectors.\n",
    "\n",
    "We will be using _svds_ function from _scipy_ package, and spliting the data using _train_test_split_ from the _sklearn_ package.\n",
    "\n",
    "#### Sparse Data and the Training Test Split\n",
    "\n",
    "The data consists of 100,004 ratings for approximately 9,066 movies by 671 users. In the wide form, the user-item matrix is composed of 6,083,286 potential user-item pairs. This means 98.35% of the user-item matrix is empty. Futhermore, there are many movies with fewer than 11 ratings, and users who have rated 20 movies or fewer. \n",
    "\n",
    "This create a challenge when randomly splitting the data into a training and test sets; that there may be users or movies in the test set who do not appear in the training set. This means there would be no data in the training set with which to make a recommendation. \n",
    "\n",
    "To get meaningful predictions from which to measure accuracy, we removed movies that had fewer than 5 ratings. We determined this by emprically removing viewers and movies from the data set until we found the fewest number of removed data that resulted in training and test sets that had identical userIds and movieIds present in both sets. We then applied the SVD matrix factorization on the trimmed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1       31     2.5  1260759144\n",
      "1       1     1029     3.0  1260759179\n",
      "2       1     1061     3.0  1260759182\n",
      "3       1     1129     2.0  1260759185\n",
      "4       1     1172     4.0  1260759205\n",
      "(88087, 4)\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1       31     2.5  1260759144\n",
      "1       1     1029     3.0  1260759179\n",
      "2       1     1061     3.0  1260759182\n",
      "3       1     1129     2.0  1260759185\n",
      "4       1     1172     4.0  1260759205\n",
      "    userId  movieId  rating  timestamp\n",
      "34       2      185     3.0  835355511\n",
      "39       2      225     3.0  835355552\n",
      "75       2      500     4.0  835355731\n",
      "87       2      587     3.0  835355779\n",
      "88       2      588     3.0  835355441\n"
     ]
    }
   ],
   "source": [
    "#Load libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load datasets\n",
    "ratings = pd.read_csv('https://raw.githubusercontent.com/akulapa/Data643-Week02/master/Data/ratings.csv')\n",
    "movies = pd.read_csv('https://raw.githubusercontent.com/akulapa/Data643-Week02/master/Data/movies.csv')\n",
    "\n",
    "#Trim the users/movies with few ratings\n",
    "#relevent_ratings_df = ratings.groupby('userId').filter(lambda x: x['userId'].count()>20) #filter out users\n",
    "relevent_ratings_df = ratings.groupby('movieId').filter(lambda x: x['movieId'].count()>5)#filter out movies\n",
    "print(relevent_ratings_df.head())\n",
    "print(relevent_ratings_df.shape)\n",
    "\n",
    "#training_test_split\n",
    "ratings_train, ratings_test = train_test_split(relevent_ratings_df, test_size = 0.2, random_state = 42)\n",
    "#keeping the data ordered helps the accuracy measure\n",
    "ratings_train = ratings_train.sort_values(by=['userId', 'movieId'])\n",
    "ratings_test = ratings_test.sort_values(by=['userId', 'movieId'])\n",
    "print(ratings_train.head())\n",
    "print(ratings_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId  1       2       3       4       5       6       7       9       \\\n",
      "userId                                                                    \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "5           0.0     0.0     4.0     0.0     0.0     0.0     0.0     0.0   \n",
      "6           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "7           3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "8           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "9           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "10          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  10      11       ...    134170  134853  136864  138036  139385  \\\n",
      "userId                    ...                                             \n",
      "1           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "2           4.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "4           4.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "5           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "6           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "7           3.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "8           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "9           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "10          0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  139644  142488  146656  148626  152081  \n",
      "userId                                           \n",
      "1           0.0     0.0     0.0     0.0     0.0  \n",
      "2           0.0     0.0     0.0     0.0     0.0  \n",
      "3           0.0     0.0     0.0     0.0     0.0  \n",
      "4           0.0     0.0     0.0     0.0     0.0  \n",
      "5           0.0     0.0     0.0     0.0     0.0  \n",
      "6           0.0     0.0     0.0     0.0     0.0  \n",
      "7           0.0     0.0     0.0     0.0     0.0  \n",
      "8           0.0     0.0     0.0     0.0     0.0  \n",
      "9           0.0     0.0     0.0     0.0     0.0  \n",
      "10          0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[10 rows x 3099 columns]\n",
      "(671, 3099)\n",
      "(671, 9066)\n",
      "(671, 3099)\n",
      "(3099, 671)\n"
     ]
    }
   ],
   "source": [
    "#make wide rating df to size M and U\n",
    "ratings_wide_df = ratings.pivot(index = 'userId', columns ='movieId', values = 'rating').fillna(0)\n",
    "relevent_ratings_wide_df = relevent_ratings_df.pivot(index = 'userId', columns ='movieId', values = 'rating').fillna(0)\n",
    "\n",
    "#Convert Users as Rows and Movies as Columns \n",
    "M_df = ratings_train.pivot(index = 'userId', columns ='movieId', values = 'rating').fillna(0)\n",
    "\n",
    "#Convert Movies as Rows and Users as Columns \n",
    "U_df = ratings_train.pivot(index = 'movieId', columns ='userId', values = 'rating').fillna(0)\n",
    "\n",
    "print(M_df.head(10))\n",
    "print(relevent_ratings_wide_df.shape)\n",
    "print(ratings_wide_df.shape)\n",
    "print(M_df.shape)\n",
    "print(U_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205\n",
       "5       1     1263     2.0  1260759151\n",
       "6       1     1287     2.0  1260759187\n",
       "7       1     1293     2.0  1260759148\n",
       "8       1     1339     3.5  1260759125\n",
       "9       1     1343     2.0  1260759131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Moves rated by user 2\n",
    "ratings_train[(ratings_train['userId'] == 1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to matrix\n",
    "R = M_df.values\n",
    "R[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "1     0.016457\n",
       "2     0.080348\n",
       "3     0.037431\n",
       "4     0.221039\n",
       "5     0.096321\n",
       "6     0.035011\n",
       "7     0.080671\n",
       "8     0.115037\n",
       "9     0.039045\n",
       "10    0.046789\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate mean for each user\n",
    "user_ratings_mean = M_df.mean(axis=1)\n",
    "user_ratings_mean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for each user\n",
    "user_ratings_mean = np.mean(R, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03404324, -0.03404324, -0.03404324, ..., -0.03404324,\n",
       "        -0.03404324, -0.03404324],\n",
       "       [-0.03484995, -0.03484995, -0.03484995, ..., -0.03484995,\n",
       "        -0.03484995, -0.03484995],\n",
       "       [ 4.94514359, -0.05485641, -0.05485641, ..., -0.05485641,\n",
       "        -0.05485641, -0.05485641],\n",
       "       ...,\n",
       "       [-0.0338819 , -0.0338819 , -0.0338819 , ..., -0.0338819 ,\n",
       "        -0.0338819 , -0.0338819 ],\n",
       "       [ 3.96999032, -0.03000968, -0.03000968, ..., -0.03000968,\n",
       "        -0.03000968, -0.03000968],\n",
       "       [ 4.88980316, -0.11019684, -0.11019684, ..., -0.11019684,\n",
       "        -0.11019684, -0.11019684]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply mean for each user\n",
    "#user_bias = user rating - user over all average \n",
    "R_bias = R - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "R_bias[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets start with entire dataset as is\n",
    "#Get number of rows and columns \n",
    "r, c = R.shape\n",
    "\n",
    "#get min of row or column size, it acts as starting value for k\n",
    "k = min(r, c)\n",
    "k = k - 1\n",
    "\n",
    "#Get SVD values for entire dataset, k value has to smaller value of ratings matrix\n",
    "U, sigma, Vt = np.linalg.svd(R, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.70683003e-03, -6.60744796e-03,  6.72960914e-03, ...,\n",
       "         7.11797294e-04,  2.39425896e-03,  3.07960590e-03],\n",
       "       [-5.71542567e-03,  1.34641115e-03,  1.69887053e-03, ...,\n",
       "         6.02551647e-03, -3.21022914e-03,  2.05803856e-04],\n",
       "       [-1.78230429e-02, -2.25316806e-02, -9.50879039e-03, ...,\n",
       "        -1.78767963e-03,  4.48129454e-03,  1.04592347e-03],\n",
       "       ...,\n",
       "       [-7.36355958e-03,  2.70275221e-03,  2.26056231e-03, ...,\n",
       "        -3.80444752e-05, -4.67554965e-03,  2.41772244e-03],\n",
       "       [-1.21976460e-02,  2.69715221e-04, -9.75255842e-03, ...,\n",
       "         5.78673957e-03,  2.89137275e-02,  3.28063256e-02],\n",
       "       [-3.76684305e-02, -1.84193190e-02,  3.83361456e-03, ...,\n",
       "         6.93542923e-03, -5.30677790e-03, -4.38898858e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user features\n",
    "U[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([414.05941258, 194.15091121, 163.32797453, 130.56253965,\n",
       "       120.97514201, 114.08081159, 112.0323004 , 100.69668522,\n",
       "        96.52757036,  91.27887535])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#diagonal matrix of singular values\n",
    "sigma[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07263298, -0.03368937, -0.01400435, ..., -0.00440009,\n",
       "        -0.00438169, -0.00389684],\n",
       "       [-0.03602984, -0.01279081,  0.0032077 , ..., -0.00852045,\n",
       "        -0.00986579, -0.00948349],\n",
       "       [-0.05993274, -0.07199533, -0.03294998, ...,  0.01097528,\n",
       "         0.00890838,  0.00914939],\n",
       "       ...,\n",
       "       [-0.02858711, -0.03540355, -0.00497156, ...,  0.00506743,\n",
       "         0.01105968,  0.00133617],\n",
       "       [ 0.01101277, -0.00028058, -0.00817115, ..., -0.01230699,\n",
       "        -0.00465995,  0.00349791],\n",
       "       [ 0.01992194,  0.01260437,  0.01046734, ..., -0.01713967,\n",
       "        -0.0108864 , -0.01194502]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie features\n",
    "Vt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.016457</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  movieId\n",
       "8   0.016457       10\n",
       "15  0.016457       17\n",
       "33  0.016457       39\n",
       "41  0.016457       47\n",
       "43  0.016457       50\n",
       "44  0.016457       52\n",
       "50  0.016457       62\n",
       "81  0.016457      110\n",
       "94  0.016457      144\n",
       "98  0.016457      150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get diagonal sigma\n",
    "sigma_diag = np.diag(sigma)\n",
    "\n",
    "#Recalculate ratings\n",
    "predicted_ratings = np.dot(np.dot(U, sigma_diag), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "#Convert to dataframe\n",
    "predicted_ratings_T = pd.DataFrame(predicted_ratings.T)\n",
    "predicted_ratings_T['movieId'] = U_df.index\n",
    "\n",
    "#Movies rated by user 1\n",
    "userMoviesId = list(ratings[(ratings['userId'] == 2)]['movieId'])\n",
    "\n",
    "#Predicted values for user 1 \n",
    "predicted_ratings_T = predicted_ratings_T[predicted_ratings_T.movieId.isin(userMoviesId)]\n",
    "predicted_ratings_T = predicted_ratings_T[[0,'movieId']].head(10)\n",
    "predicted_ratings_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are predicted movie ratings for _user-1_. Ratings are very close to actual ratings. Root mean square error is very low, $0.19$. Note that with the full data set, the RMSE is even lower, $0.10$. As expected putting 20% of the data into a test set did reduce the accuracy of the model. Low error is expected as we used _k_ value as full set. It also suggests that is is _overfitting_. As we lower _k_ value error is expected to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.19913087852627426\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(predicted_ratings, R)**0.5\n",
    "print(\"RMSE : \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.199 Frobenius Norm : 287.422 k-Value reduced by : 0 Singlar Value Ratio : 1.0\n",
      "RMSE : 0.2 Frobenius Norm : 287.76 k-Value reduced by : 13 Singlar Value Ratio : 0.994\n",
      "RMSE : 0.206 Frobenius Norm : 297.127 k-Value reduced by : 98 Singlar Value Ratio : 0.976\n",
      "RMSE : 0.226 Frobenius Norm : 326.016 k-Value reduced by : 212 Singlar Value Ratio : 0.947\n",
      "RMSE : 0.254 Frobenius Norm : 366.266 k-Value reduced by : 304 Singlar Value Ratio : 0.909\n",
      "RMSE : 0.288 Frobenius Norm : 414.672 k-Value reduced by : 379 Singlar Value Ratio : 0.862\n",
      "RMSE : 0.324 Frobenius Norm : 467.02 k-Value reduced by : 440 Singlar Value Ratio : 0.812\n",
      "RMSE : 0.359 Frobenius Norm : 517.262 k-Value reduced by : 487 Singlar Value Ratio : 0.756\n",
      "RMSE : 0.394 Frobenius Norm : 567.688 k-Value reduced by : 526 Singlar Value Ratio : 0.697\n",
      "RMSE : 0.427 Frobenius Norm : 616.321 k-Value reduced by : 558 Singlar Value Ratio : 0.635\n",
      "RMSE : 0.46 Frobenius Norm : 663.893 k-Value reduced by : 585 Singlar Value Ratio : 0.576\n",
      "RMSE : 0.49 Frobenius Norm : 706.067 k-Value reduced by : 606 Singlar Value Ratio : 0.519\n",
      "RMSE : 0.517 Frobenius Norm : 744.886 k-Value reduced by : 623 Singlar Value Ratio : 0.467\n",
      "RMSE : 0.54 Frobenius Norm : 778.232 k-Value reduced by : 636 Singlar Value Ratio : 0.425\n",
      "RMSE : 0.558 Frobenius Norm : 804.505 k-Value reduced by : 645 Singlar Value Ratio : 0.393\n",
      "RMSE : 0.571 Frobenius Norm : 823.634 k-Value reduced by : 651 Singlar Value Ratio : 0.363\n",
      "RMSE : 0.583 Frobenius Norm : 841.405 k-Value reduced by : 656 Singlar Value Ratio : 0.342\n",
      "RMSE : 0.592 Frobenius Norm : 853.494 k-Value reduced by : 659 Singlar Value Ratio : 0.327\n",
      "RMSE : 0.598 Frobenius Norm : 862.212 k-Value reduced by : 661 Singlar Value Ratio : 0.318\n"
     ]
    }
   ],
   "source": [
    "#Lets loop through reducing k value\n",
    "k = min(r, c)\n",
    "for i in range(5, 100, 5):\n",
    "\n",
    "    # take columns less than k from U\n",
    "    U_p = U[:,:k]\n",
    "    # take rows less than k from V\n",
    "    V_p = Vt[:k,:]\n",
    "    # build the new S matrix with top k diagnal elements\n",
    "    S_p = np.zeros((k, k), int)\n",
    "    for j in range(k):\n",
    "        S_p[j][j] = sigma[j]\n",
    "    \n",
    "    #Recalculate ratings\n",
    "    predicted_ratings = np.dot(np.dot(U_p, S_p), V_p) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "    #Calculate error difference\n",
    "    diffM = R - predicted_ratings\n",
    "    \n",
    "    #Frobenius Norm\n",
    "    frobeniusNorm = np.linalg.norm(diffM, 'fro')\n",
    "    \n",
    "    #Singular value ratio has to be 90%\n",
    "    if (k == min(r, c)):\n",
    "        sigma_ratio = round(sum(sigma**2)/sum(sigma**2),3)\n",
    "    else:\n",
    "        less_singular_values = sigma[ np.where( sigma >= i ) ]\n",
    "        sigma_ratio = round(sum(less_singular_values**2)/sum(sigma**2),3)\n",
    "    \n",
    "    \n",
    "    #RMSE\n",
    "    rmse = mean_squared_error(predicted_ratings, R)**0.5\n",
    "    print(\"RMSE : \" + str(round(rmse,3)) + \n",
    "          ' Frobenius Norm : ' + str(round(frobeniusNorm,3)) + \n",
    "          ' k-Value reduced by : ' + str(min(r, c) - k) + \n",
    "          ' Singlar Value Ratio : ' + str(sigma_ratio)\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Eliminate rows with low sigma value\n",
    "    k = min(r, c) - sigma[ np.where( sigma < i ) ].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_RMSE_, increases as we reduce of _k-value_. Based on the video https://www.youtube.com/watch?v=c7e-D2tmRE0&index=49&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV, single value ratio holds good even when we reduce 304 dimensions. This was 329 dimensions when the full data set was used.\n",
    "\n",
    "Now we have to construct a data frame of predicted ratings for the user-movie pairs that are included in the test set. We expanded the code we used in Project 3 where we select predictions for a single user to loop through all users and append the necessary data for each user in order of userId. This will facilitate the comparsion of the predicted rating to actual rating in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Rated  movieId                Watched  \\\n",
      "0 -0.328764      185        Net, The (1995)   \n",
      "1  0.152279      225      Disclosure (1994)   \n",
      "2  0.385437      500  Mrs. Doubtfire (1993)   \n",
      "3  0.140395      587           Ghost (1990)   \n",
      "4  0.086322      588         Aladdin (1992)   \n",
      "\n",
      "                                        genres  \n",
      "0                        Action|Crime|Thriller  \n",
      "1                               Drama|Thriller  \n",
      "2                                 Comedy|Drama  \n",
      "3        Comedy|Drama|Fantasy|Romance|Thriller  \n",
      "4  Adventure|Animation|Children|Comedy|Musical  \n",
      "    userId  movieId  rating  timestamp\n",
      "34       2      185     3.0  835355511\n",
      "39       2      225     3.0  835355552\n",
      "75       2      500     4.0  835355731\n",
      "87       2      587     3.0  835355779\n",
      "88       2      588     3.0  835355441\n"
     ]
    }
   ],
   "source": [
    "#Number of dimensions\n",
    "k = 367\n",
    "# take columns less than k from U\n",
    "U_p = U[:,:k]\n",
    "# take rows less than k from V\n",
    "V_p = Vt[:k,:]\n",
    "# build the new S matrix with top k diagnal elements\n",
    "S_p = np.zeros((k, k), int)\n",
    "for j in range(k):\n",
    "    S_p[j][j] = sigma[j]\n",
    "\n",
    "#Recalculate ratings_test\n",
    "predicted_ratings = np.dot(np.dot(U_p, S_p), V_p) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "#Convert to dataframe\n",
    "predicted_ratings_T = pd.DataFrame(predicted_ratings.T)\n",
    "predicted_ratings_T['movieId'] = U_df.index\n",
    "\n",
    "#Movies rated by users 1-671\n",
    "\n",
    "\n",
    "userMoviesId = []\n",
    "estimated_ratings_test_T = pd.DataFrame()\n",
    "max_user = len(M_df.index)+1 #The range function is not inclusive on the upper limit.\n",
    "for u in range(1,max_user):\n",
    "    userMoviesId = []\n",
    "    #if ratings_test.loc[\"\"]\n",
    "    userMoviesId = list(ratings_test[(ratings_test['userId'] == u)]['movieId'])\n",
    "\n",
    "#Predicted values for user 1\n",
    "    user_ratings_test_T = pd.DataFrame()\n",
    "    #frames = []\n",
    "    user_ratings_test_T = predicted_ratings_T[predicted_ratings_T.movieId.isin(userMoviesId)]\n",
    "    user_ratings_test_T = user_ratings_test_T[[u-1,'movieId']]\n",
    "    user_ratings_test_T = pd.merge(user_ratings_test_T, movies, on='movieId', how='inner')\n",
    "    user_ratings_test_T = user_ratings_test_T[[u-1, 'movieId', 'title', 'genres']]\n",
    "    user_ratings_test_T.columns = ['Rated', 'movieId', 'Watched','genres']\n",
    "    #print(user_ratings_test_T.head())\n",
    "    #frames = [estimated_ratings_test_T, user_ratings_test_T]\n",
    "    estimated_ratings_test_T = estimated_ratings_test_T.append(user_ratings_test_T)\n",
    "\n",
    "\n",
    "\n",
    "print(estimated_ratings_test_T.head())\n",
    "print(ratings_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Confusion Matrix\n",
    "\n",
    "Now that we have estimations that match the user-item pairs in the test set we can now form a confusion matrix. The confusion matrix is a $2x2$ matrix where the diagonal terms are the true positives, where we predict the person likes the movie and they rate it favorably, and the true negatives, where we predict the user will not like the movie and they rate it unfavorably. The off-diagonal terms are the false positives, where we say the user will like the movie, but they rate it unfavorably, and false negatives, where we say the user will not like the movie but they rate it favorably.\n",
    "\n",
    "As stated in Project 3, The SVD method calculates known values with a high amount of accuracy: a RMSE $<0.1$. For unknown values, the SVD method trying the calculate the value imputted for NAN's, zero in our case. However, we removed bais form the data before we factorized the user-item matrix. We then put the bias back into the matrix after it was estimated by SVD. Therefore, the values computed for the missing value should be an estimate of user recommendation, but centered on zero and not 1-5 like the user ratings. \n",
    "\n",
    "We shopped around around for a function in a prexisting module to create a confusion matrix automatically, however we did not find one that matched our use case. We wrote our own code using two dataframes, one containing predicted ratings and movieIds in order of userIds and the test set which contains userId, movieId and actual ratings from the user.  We simply looped through the data frames and compared predictions to ratings. The  favorable threshold for the prediction was set at 0 and the favorable thershold for the ratings was set at 3.0. We then incremented the corresponding counter for true positives, true negatives, false positives, and false negatives respectively. We then inputted these values into a Numpy Array to create the confusion matrix.\n",
    "\n",
    "We were also able to compute key measurements from the confusion matrix data: Accuracy, Precision, Recall, and F1 score. \n",
    "\n",
    "Accuracy is the rate at which a prediction is correct and is the determined by the formula: $A = \\frac{TP+TN}{TP+TN+FP+FN}$.\n",
    "\n",
    "Precision is the rate at which a positive prediction is accually positive and is the determined by the formula: $P = \\frac{TP}{TP+FP}$.\n",
    "\n",
    "Recall is the rate at which true positive outcome predicted from the total positive outcomes reported and is the determined by the formula: $R = \\frac{TP}{TP+FN}$.\n",
    "\n",
    "The F1 score is a harmonic average of the precision and recall, where both are measures of correct positive predictions compared to predicted positive outcomes and actual postive outcomes respectively. The F1 score is determined by the formula: $F1 = \\frac{2*P*R}{P+R}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13593  2801]\n",
      " [ 1052   172]]\n"
     ]
    }
   ],
   "source": [
    "#movies.shape\n",
    "#print(estimated_ratings_test_T.head())\n",
    "#print(ratings.head())\n",
    "TP = 0 #True Positive\n",
    "TN = 0 #True Negative\n",
    "FP = 0 #False Positive\n",
    "FN = 0 #False Negative\n",
    "    \n",
    "max_rate = estimated_ratings_test_T.shape[0]\n",
    "for i in range(max_rate):\n",
    "        if estimated_ratings_test_T.iloc[i,1] == ratings_test.iloc[i,1]:\n",
    "            #print(str(estimated_ratings_test_T.iloc[i,0]) + ' ' +str(ratings_test.iloc[i,2]))\n",
    "            if estimated_ratings_test_T.iloc[i,0] >= 0 and ratings_test.iloc[i,2] >= 3:\n",
    "                TP += 1\n",
    "            elif  estimated_ratings_test_T.iloc[i,0] < 0 and ratings_test.iloc[i,2] < 3:\n",
    "                TN += 1\n",
    "            elif estimated_ratings_test_T.iloc[i,0] >= 0 and ratings_test.iloc[i,2] < 3:\n",
    "                FP += 1\n",
    "            elif estimated_ratings_test_T.iloc[i,0] < 0 and ratings_test.iloc[i,2] >= 3:\n",
    "                FN += 1    \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "conf = np.array([[TP,FP],[FN,TN]])\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7813032126234533\n",
      "Precision is: 0.8291448090764914\n",
      "Recall is: 0.9281666097644247\n",
      "F1 score is: 0.8758658461934984\n"
     ]
    }
   ],
   "source": [
    "accuracy = (conf[0,0]+ conf[1,1])/estimated_ratings_test_T.shape[0]\n",
    "print(\"Accuracy is: \" + str(accuracy))\n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision is: \" + str(precision))\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall is: \" + str(recall))\n",
    "F1 = (2*precision*recall)/(precision+recall)\n",
    "print(\"F1 score is: \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=ratings['rating'].value_counts().index, y=ratings['rating'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Singular value decomposition predicts positive outcomes well.\n",
    "- SVD tends to report negative values as false positives.\n",
    "- This could be due to the ratings data having mostly postive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "- http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm\n",
    "- https://beckernick.github.io/matrix-factorization-recommender/\n",
    "- https://github.com/beckernick/matrix_factorization_recommenders\n",
    "- https://www.youtube.com/watch?v=yLdOS6xyM_Q&feature=youtu.be&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV\n",
    "- https://www.youtube.com/watch?v=c7e-D2tmRE0&index=49&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV\n",
    "- https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75\n",
    "- https://github.com/mutaphore/svd-image-compression/blob/master/image_compression.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
